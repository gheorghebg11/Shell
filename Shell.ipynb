{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shell.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "IhDqpEz1xG3u",
        "JNN8go-BB9RJ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ksXJw2tBpWrW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load the files into Colab"
      ]
    },
    {
      "metadata": {
        "id": "tc6x8y9H5IlK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First we'll upgrade pandas, as it requires a runtime restart, so let's get this out of the way. The old version on Colab doesn't allow you to access series via df.col_name, and it's annoying in f-strings."
      ]
    },
    {
      "metadata": {
        "id": "LMWBCgqu5JJV",
        "colab_type": "code",
        "outputId": "7f0e6cb1-bfac-4416-cd89-4d13a6032c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pandas #need to upgrade otherwise colab doesn't understand the command df.column_name"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 10.1MB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 0.23.4\n",
            "    Uninstalling pandas-0.23.4:\n",
            "      Successfully uninstalled pandas-0.23.4\n",
            "Successfully installed pandas-0.24.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Du26elpK20Ho",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Don't forget to press the 'RESTART RUNTIME' button above."
      ]
    },
    {
      "metadata": {
        "id": "FKZMLM-S16Nd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first cells are for loading the big data files from google drive (as colab only keeps the files for 12 hours), and the .csv from my local drive or dropbox. We first authenticate."
      ]
    },
    {
      "metadata": {
        "id": "WzIkU8LMyozt",
        "colab_type": "code",
        "outputId": "76cef6fb-7ffc-41e0-8a24-4d1b1eaca4d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install PyDrive\n",
        "import os, zipfile\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth, files\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyDrive\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n",
            "\u001b[K    100% |████████████████████████████████| 993kB 23.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.12.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.5)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.5)\n",
            "Building wheels for collected packages: PyDrive\n",
            "  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n",
            "Successfully built PyDrive\n",
            "Installing collected packages: PyDrive\n",
            "Successfully installed PyDrive-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dEMiyKPeq9Hw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now download the files and un unzip the archives. We have to use 7z for train_curated.zip since I believe it's a bad file or \n",
        "it's too big. Either way unzip does not work, but works for test.zip"
      ]
    },
    {
      "metadata": {
        "id": "dWbpFmwVqgxv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir /content/data\n",
        "print('\\nDownloading the data')\n",
        "download = drive.CreateFile({'id': '1e5u2uDQ5mupV64KJbmWVG-JhlGKz9uUD'})\n",
        "download.GetContentFile('/content/data_shell.tar.gz')\n",
        "!tar -xzvf /content/data_shell.tar.gz -C /content/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IhDqpEz1xG3u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Visualization and Basic Cleaning (can skip and go to Model directly)"
      ]
    },
    {
      "metadata": {
        "id": "dqBNmbTp12LL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First load some packages for Data Visualization."
      ]
    },
    {
      "metadata": {
        "id": "1GgouP0vzvop",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(1989)\n",
        "\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from IPython.display import display\n",
        "pd.options.display.max_columns = 20\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lCb-h9hm0Mgp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now load the spreadsheet data to explore it a little bit."
      ]
    },
    {
      "metadata": {
        "id": "i45IxsCd0MWJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dir_data = '/content/data/'\n",
        "#train = pd.read_csv(os.path.join(dir_data, 'train_curated.csv'))\n",
        "#test = pd.read_csv(os.path.join(dir_data, 'sample_submission.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ou05IqYl_W5o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Some files from the training set are corrupted (very few) and won't unzip, we erase those from the spreadsheet."
      ]
    },
    {
      "metadata": {
        "id": "pdD0NsgB-_9u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files_in_folder = [name for name in os.listdir(dir_data)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CXozKqnwAK4w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Look at the shape and number of examples and labels. "
      ]
    },
    {
      "metadata": {
        "id": "-cLQ9amV2DPD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f'Train set has {train.shape[0]} examples and {len(set(train.labels))} different labels')\n",
        "train.sample(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nqZCmtik2N5D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f'Test set has {test.shape[0]} examples and {len(test.columns[1:])} different labels')\n",
        "test.sample(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kHNxz_HB4szP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will for now exclude the sounds which have multiple labels."
      ]
    },
    {
      "metadata": {
        "id": "WGrqELSj2N9U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = train[train['labels'].isin(test.columns[1:])]\n",
        "print(f'Removing multilabel examples. The Train set has now {train.shape[0]} examples and {len(set(train.labels))} different labels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8X5o1jcF48s3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's visualize how many samples there are per label."
      ]
    },
    {
      "metadata": {
        "id": "mQxcK7Ja49du",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "category_group = train.groupby(['labels']).count()\n",
        "category_group.columns = ['counts']\n",
        "print(f'The number of training clips per label range from {category_group.counts.min()} to {category_group.counts.max()}')\n",
        "plot = category_group.sort_values(ascending=True, by='counts').plot(kind='barh', title='nbr training audio clips per label', figsize=(20,12))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Cs9GgL886Z6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now visualize the distribution of their length:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GPdoJyuj9nHU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We first only look at the top 25 categories"
      ]
    },
    {
      "metadata": {
        "id": "EQZi4Kii9bcL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train['nframes'] = train['fname'].apply(lambda fname : wave.open(os.path.join(dir_data, 'curated', fname)).getnframes())\n",
        "test['nframes'] = test['fname'].apply(lambda fname : wave.open(os.path.join(dir_data, 'test', fname)).getnframes())\n",
        "# plot the distribution of top 25 catetegories of the training set, since 74 is a little bit too much\n",
        "idx_25_top = category_group.sort_values(ascending=True, by='counts').index[-25:]\n",
        "_, ax = plt.subplots(figsize=(25,10))\n",
        "sns.violinplot(data = train[train.labels.isin(idx_25_top)], x='labels', y='nframes')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C54lYlg1AETw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And now compare the training and the test set."
      ]
    },
    {
      "metadata": {
        "id": "jhxUsewn9bh6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(2,1, figsize=(20,8))\n",
        "train.nframes.plot(kind='hist', bins=100, rwidth=0.5, ax = ax[0])\n",
        "test.nframes.plot(kind='hist', bins=100, rwidth=0.5, ax = ax[1])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aBhfg6mRBF5A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see that it's not the same scale, there are some outliers in the training set stretching the x-axis. We'll get rid of those."
      ]
    },
    {
      "metadata": {
        "id": "LO_42LPD9bkc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f'Here are the outliers: \\n{train[train.nframes > 1500000]}')\n",
        "train = train[train['nframes']< 1500000]\n",
        "print('We remove it!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WWEXiQBv9Zp-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's pick a random audio clip and look at its attributes."
      ]
    },
    {
      "metadata": {
        "id": "f69j6eQH49f5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rand_ex = train.sample(1)\n",
        "fname = rand_ex['fname'].values[0]\n",
        "path_audiofile = os.path.join(dir_data, 'curated', fname)\n",
        "wav = wave.open(path_audiofile)\n",
        "print(f'Filename is {fname}')\n",
        "print(f'Sampling frame rate {wav.getframerate()}')\n",
        "print(f'Total frames {wav.getnframes()}')\n",
        "print(f'Duration {wav.getnframes() / wav.getframerate()} sec')\n",
        "print(f'Label is {rand_ex.labels.values[0]} \\n' )\n",
        "import IPython\n",
        "IPython.display.Audio(path_audiofile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sM6T3O9I49kx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rate, data = wavfile.read(path_audiofile)\n",
        "plt.plot(data)\n",
        "plt.figure(figsize=(18,4)); plt.plot(data[:500], '.'); plt.plot(data[:500], '-')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hsvm9WuJVxcH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate MFCC and visualize it."
      ]
    },
    {
      "metadata": {
        "id": "-7Lzyng8VxOt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SAMPLE_RATE = 44100\n",
        "wav, _ = librosa.core.load(path_audiofile, sr=SAMPLE_RATE)\n",
        "wav = wav[:2*44100] # keep 1 sec\n",
        "mfcc = librosa.feature.mfcc(wav, sr = SAMPLE_RATE, n_mfcc=40)\n",
        "print(f'Shape of the MFCC is {mfcc.shape}')\n",
        "_, ax = plt.subplots(figsize=(15, 5))\n",
        "ax.imshow(mfcc, cmap='Spectral', interpolation='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "amS6TzdR9Hbj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally we now save this cleaned dataframe."
      ]
    },
    {
      "metadata": {
        "id": "Zz2dWcyJ9F_j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train.to_csv(os.path.join(dir_data, 'train_curated_clean.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JNN8go-BB9RJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Construct The Model"
      ]
    },
    {
      "metadata": {
        "id": "eRb_Jb_2E9S7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First (Re)Load some Packages"
      ]
    },
    {
      "metadata": {
        "id": "tgzcJyleELS5",
        "colab_type": "code",
        "outputId": "449aaee7-e3d3-4166-facc-db205c9db126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(1989)\n",
        "\n",
        "import os, shutil\n",
        "\n",
        "import librosa, scipy, wave\n",
        "from scipy.io import wavfile\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras import losses, models, optimizers\n",
        "from keras.activations import relu, softmax\n",
        "from keras.callbacks import (EarlyStopping, LearningRateScheduler, ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
        "from keras.layers import (Convolution1D, Dense, Dropout, GlobalAveragePooling1D, GlobalMaxPool1D, Input, MaxPool1D, concatenate) # for the 1D conv models\n",
        "from keras.layers import (Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten, GlobalMaxPool2D, MaxPool2D, Activation, concatenate) # for the 2D models with MFCC\n",
        "from keras.utils import Sequence, to_categorical\n",
        "from keras import backend as K\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jwyBlvquSv3R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the data, add some columns and set up some dictionnaries."
      ]
    },
    {
      "metadata": {
        "id": "mztnLIJ_F-az",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dir_data = '/content'\n",
        "train = pd.read_csv(os.path.join(dir_data, 'train_curated_clean.csv'))\n",
        "test = pd.read_csv(os.path.join(dir_data, 'sample_submission.csv'))\n",
        "\n",
        "labels = list(train.labels.unique())\n",
        "label_to_idx = {label: i for i, label in enumerate(labels)}\n",
        "\n",
        "train.set_index(\"fname\", inplace=True)\n",
        "test.set_index(\"fname\", inplace=True)\n",
        "train[\"label_idx\"] = train.labels.apply(lambda x: label_to_idx[x])\n",
        "\n",
        "category_group = train.groupby(['labels']).count()\n",
        "category_group.rename(columns={'labels':'counts'})\n",
        "\n",
        "# these are some parameters for the size of the run.\n",
        "tiny_run = 100\n",
        "small_run = 1000\n",
        "all_run = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ru4064DxXt8N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Some Preliminary Functions:\n",
        "\n",
        "The Normalization function - Simple normalization in the range [0,1], and then shift to 0-mean [-0.5,0.5]."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ku2F7qu1sct6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def audio_norm(data):\n",
        "    max_data = np.max(data)\n",
        "    min_data = np.min(data)\n",
        "    data = (data-min_data)/(max_data-min_data+1e-6)\n",
        "    return data - 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ADqZrrUSGWgO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Configuration class : In particular contains the default settings."
      ]
    },
    {
      "metadata": {
        "id": "2WnwsyPIGQ1V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Config(object):\n",
        "\tdef __init__(self, model_name = None, sampling_rate=16000, audio_duration=2, use_mfcc=False, n_mfcc=20, n_classes=len(category_group), n_folds=5, learning_rate=0.0001, max_epochs=10):\n",
        "\t\tself.sampling_rate = sampling_rate\n",
        "\t\tself.audio_duration = audio_duration\n",
        "\t\tself.use_mfcc = use_mfcc\n",
        "\t\tself.n_mfcc = n_mfcc\n",
        "\t\tself.n_classes = n_classes\n",
        "\t\tself.n_folds = n_folds\n",
        "\t\tself.learning_rate = learning_rate\n",
        "\t\tself.max_epochs = max_epochs\n",
        "\t\tself.model_name = model_name\n",
        "\t\tif self.model_name == None:\n",
        "\t\t    model_name = 'dummy1d'\n",
        "\t\t    if use_mfcc:\n",
        "\t\t\t    model_name = 'dummy2d'\n",
        "        \n",
        "        \n",
        "\t\tself.audio_length = self.audio_duration * self.sampling_rate\n",
        "\n",
        "\t\tif self.use_mfcc:\n",
        "\t\t\tself.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length / 512)), 1)\n",
        "\t\telse:\n",
        "\t\t\tself.dim = (self.audio_length, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6y1g4Yt9Gk7E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Datagenerator class : Inherits from Keras.utils.Sequence to efficiently feed the data.\n",
        "\n",
        "I think that the normalization is done batch by batch, which is not good, as it's done the same way on the test set. "
      ]
    },
    {
      "metadata": {
        "id": "Q_cpm0v2Gf_u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence): # Inherits from Keras.utils.Sequence for multiprocessing\n",
        "\n",
        "    def __init__(self, config, dir_data, list_IDs, labels=None,\n",
        "\t\t\t\t\tbatch_size=64, shuffle=False, preprocessing_fn=lambda x: x):\n",
        "        self.config = config\n",
        "        self.dir_data = dir_data\n",
        "        self.list_IDs = list_IDs\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.preprocessing_fn = preprocessing_fn\n",
        "        self.shuffle = shuffle ## DOES IT WORK TO HAVE TRUE ?\n",
        "        self.on_epoch_end()\n",
        "        self.dim = self.config.dim\n",
        "\n",
        "    # returns the number of batches in the Sequence (usually per 1 epoch)\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    # returns a complete batch at the place index\n",
        "    def __getitem__(self,index):\n",
        "        indexes_temp = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes_temp]\n",
        "        return self.__data_generation(list_IDs_temp)\n",
        "\n",
        "    # called at the end of an epoch: reloads IDs\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        cur_batch_size = len(list_IDs_temp)\n",
        "        X = np.empty((cur_batch_size, *self.dim))\n",
        "        \n",
        "        input_length = self.config.audio_length\n",
        "        for i,ID in enumerate(list_IDs_temp):\n",
        "            file_path = os.path.join(self.dir_data, ID)\n",
        "            \n",
        "            # read and resample\n",
        "            data, _ = librosa.core.load(file_path, sr=self.config.sampling_rate, res_type='kaiser_fast')\n",
        "            \n",
        "            # random crop or pad\n",
        "            if len(data) > input_length:\n",
        "                max_offset = len(data) - input_length\n",
        "                offset = np.random.randint(max_offset)\n",
        "                data = data[offset:offset+input_length]\n",
        "            else:\n",
        "                if input_length > len(data):\n",
        "                    max_offset = input_length - len(data)\n",
        "                    offset = np.random.randint(max_offset)\n",
        "                else:\n",
        "                    offset = 0\n",
        "                data = np.pad(data, (offset, input_length-offset-len(data)), 'constant')\n",
        "            \n",
        "            # normalize + other preprocesses\n",
        "            if self.config.use_mfcc:\n",
        "                data = librosa.feature.mfcc(data, sr=self.config.sampling_rate, n_mfcc=self.config.n_mfcc)\n",
        "                data = np.expand_dims(data,-1) #add a dimension at the end\n",
        "                #data = self.preprocessing_fn(data) # don't need norm in this case as we use BN\n",
        "            else:\n",
        "                data = self.preprocessing_fn(data)[:, np.newaxis]\n",
        "            \n",
        "            # save in the big array X\n",
        "            X[i,] = data\n",
        "        \n",
        "        if self.labels is not None:\n",
        "            y = np.empty(cur_batch_size, dtype=int)\n",
        "            for i, ID in enumerate(list_IDs_temp):\n",
        "                y[i] = self.labels[ID]\n",
        "            \n",
        "            return X, to_categorical(y, num_classes=self.config.n_classes)\n",
        "        else:\n",
        "            return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R0Dt5RVfYe9n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a dummy model: Just to debug and test the pipeline. Name = dummy1d"
      ]
    },
    {
      "metadata": {
        "id": "a8k0hgQkXnhl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_1d_dummy_model(config):\n",
        "    n_class = config.n_classes\n",
        "    input_length = config.audio_length\n",
        "    \n",
        "    inp = Input(shape=(input_length,1))\n",
        "    x = GlobalMaxPool1D()(inp)\n",
        "    out = Dense(n_class, activation=softmax)(x)\n",
        "    \n",
        "    model = models.Model(inputs=inp, outputs=out)\n",
        "    opt = optimizers.Adam(config.learning_rate)\n",
        "    \n",
        "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SxXo2ZLVhOFB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a better model: Still simple architecture though. Name = conv1d"
      ]
    },
    {
      "metadata": {
        "id": "wK5WgWGchbJc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_1d_conv_model(config):\n",
        "    \n",
        "    nclass = config.n_classes\n",
        "    input_length = config.audio_length\n",
        "    \n",
        "    inp = Input(shape=(input_length,1))\n",
        "    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(inp)\n",
        "    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(x)\n",
        "    x = MaxPool1D(16)(x)\n",
        "    x = Dropout(rate=0.1)(x)\n",
        "    \n",
        "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
        "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
        "    x = MaxPool1D(4)(x)\n",
        "    x = Dropout(rate=0.1)(x)\n",
        "    \n",
        "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
        "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
        "    x = MaxPool1D(4)(x)\n",
        "    x = Dropout(rate=0.1)(x)\n",
        "    \n",
        "    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n",
        "    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n",
        "    x = GlobalMaxPool1D()(x)\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "\n",
        "    x = Dense(64, activation=relu)(x)\n",
        "    x = Dense(1028, activation=relu)(x)\n",
        "    out = Dense(nclass, activation=softmax)(x)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=out)\n",
        "    opt = optimizers.Adam(config.learning_rate)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v2_qJX-aY8QI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here is the dummy 2d model that applies to the audio data after MFCC. Name = dummy2d"
      ]
    },
    {
      "metadata": {
        "id": "q9SoBNfgY7py",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_2d_dummy_model(config):\n",
        "    \n",
        "    nclass = config.n_classes\n",
        "    \n",
        "    inp = Input(shape=(config.dim[0],config.dim[1],1))\n",
        "    x = GlobalMaxPool2D()(inp)\n",
        "    out = Dense(nclass, activation=softmax)(x)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=out)\n",
        "    opt = optimizers.Adam(config.learning_rate)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Euw448aY7cR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And the larger 2D conv model. Name = conv2d"
      ]
    },
    {
      "metadata": {
        "id": "9fN2n-9JY815",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_2d_conv_model(config):\n",
        "    \n",
        "    nclass = config.n_classes\n",
        "    \n",
        "    inp = Input(shape=(config.dim[0],config.dim[1],1))\n",
        "    x = Convolution2D(32, (4,10), padding=\"same\")(inp)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = MaxPool2D()(x)\n",
        "    \n",
        "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = MaxPool2D()(x)\n",
        "    \n",
        "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = MaxPool2D()(x)\n",
        "    \n",
        "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = MaxPool2D()(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    out = Dense(nclass, activation=softmax)(x)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=out)\n",
        "    opt = optimizers.Adam(config.learning_rate)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6TJhUuuHYXG9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run The Model!"
      ]
    },
    {
      "metadata": {
        "id": "VTmdu86ciq92",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set-up the Paths for the data"
      ]
    },
    {
      "metadata": {
        "id": "LOiwhPZ9irGk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dir_log = os.path.join(dir_data, 'logs')\n",
        "if os.path.isdir(dir_log):\n",
        "        shutil.rmtree(dir_log)\n",
        "\n",
        "dir_pred = os.path.join(dir_data, 'pred')\n",
        "if os.path.isdir(dir_pred):\n",
        "    shutil.rmtree(dir_pred)\n",
        "os.mkdir(dir_pred)\n",
        "\n",
        "dir_train = os.path.join(dir_data, 'curated')\n",
        "dir_test = os.path.join(dir_data, 'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G8wNpXt0Y_uH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creating the config and other necessary objects"
      ]
    },
    {
      "metadata": {
        "id": "qpdMk0pbYZFG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "config = Config(sampling_rate=44100, model_name = 'conv2d', audio_duration=5, n_folds=3, learning_rate=0.001, max_epochs=50, use_mfcc = True, n_mfcc = 40)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=config.n_folds)\n",
        "\n",
        "size_of_run = all_run # choose in [tiny_run, small_run, all_run]\n",
        "\n",
        "train = train[:size_of_run]\n",
        "test = test[:size_of_run]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c0f9w0QwbHIB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run the Loop"
      ]
    },
    {
      "metadata": {
        "id": "B8R9e3jvZufP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if os.path.isdir(dir_log):\n",
        "        shutil.rmtree(dir_log)\n",
        "if os.path.isdir(dir_pred):\n",
        "    shutil.rmtree(dir_pred)\n",
        "os.mkdir(dir_pred)\n",
        "\n",
        "for i, (train_split, val_split) in enumerate(skf.split(train.index, train.label_idx)):\n",
        "    K.clear_session()\n",
        "    \n",
        "    train_set = train.iloc[train_split]\n",
        "    val_set = train.iloc[val_split]\n",
        "    \n",
        "    callbacks_list= []\n",
        "    \n",
        "    # the checkpoint is causing issues with colab and breaks in the middle of training. A workaround is the restore_best_weights from EarlyStopping\n",
        "    #checkpoint = ModelCheckpoint(os.path.join(dir_log,'best_%d.h5'%i), monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    #callbacks_list.append(checkpoint)  \n",
        "    \n",
        "    early = EarlyStopping(monitor='val_loss', mode='min', patience=5, restore_best_weights=True)\n",
        "    callbacks_list.append(early)\n",
        "    \n",
        "    tb = TensorBoard(log_dir= os.path.join(dir_log, 'fold_%d'%i), write_graph=True)\n",
        "    callbacks_list.append(tb)    \n",
        "    \n",
        "    print(\"#\"*50)\n",
        "    print(f'\\nFold {i}')\n",
        "    \n",
        "    if config.model_name == 'conv1d':\n",
        "        model = get_1d_conv_model(config)\n",
        "    elif config.model_name == 'conv2d':\n",
        "        model = get_2d_conv_model(config)\n",
        "    elif config.model_name == 'dummy2d':\n",
        "        model = get_2d_dummy_model(config)\n",
        "    else:\n",
        "        model = get_1d_dummy_model(config)\n",
        "    \n",
        "    train_generator = DataGenerator(config, dir_train, train_set.index, labels=train_set.label_idx,\n",
        "\t\t\t\t\tbatch_size=64) #, preprocessing_fn=audio_norm)\n",
        "    val_generator = DataGenerator(config, dir_train, val_set.index, labels=val_set.label_idx,\n",
        "\t\t\t\t\tbatch_size=64) #, preprocessing_fn=audio_norm)\n",
        "\n",
        "    history = model.fit_generator(train_generator, callbacks=callbacks_list, validation_data=val_generator, epochs=config.max_epochs, use_multiprocessing=True, max_queue_size=20)\n",
        "    \n",
        "    model.save(os.path.join(dir_log,'best_%d.h5'%i))\n",
        "    \n",
        "    # training done, now load best model (at what epoch it was best) and predict\n",
        "    model.load_weights(os.path.join(dir_log,'best_%d.h5'%i))\n",
        "    \n",
        "    # save train prediction for error analysis\n",
        "    train_generator = DataGenerator(config, dir_train, train_set.index, labels=train_set.label_idx,\n",
        "\t\t\t\t\tbatch_size=64) #, preprocessing_fn=audio_norm)\n",
        "    \n",
        "    predictions = model.predict_generator(train_generator, use_multiprocessing=True, max_queue_size=20, verbose=1)\n",
        "    np.save(os.path.join(dir_pred, 'train_pred_%d.npy'%i), predictions)\n",
        "    \n",
        "    # save test prediction\n",
        "    test_generator = DataGenerator(config, dir_test, test.index, labels=None,\n",
        "\t\t\t\t\tbatch_size=64) #, preprocessing_fn=audio_norm)\n",
        "    \n",
        "    predictions = model.predict_generator(test_generator, use_multiprocessing=True, max_queue_size=20, verbose=1)\n",
        "    np.save(os.path.join(dir_pred, 'test_pred_%d.npy'%i), predictions)\n",
        "    pred_test_shape = predictions.shape\n",
        "\n",
        "    # Make a submission file\n",
        "    top_3 = np.array(labels)[np.argsort(-predictions, axis=1)[:, :3]]\n",
        "    predicted_labels = [' '.join(list(x)) for x in top_3]\n",
        "    test['label'] = predicted_labels\n",
        "    test[['label']].to_csv(os.path.join(dir_pred, 'predictions_%d.csv'%i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hKOd2zzhqAZc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BpsqnFZGbNf6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ensemble the Predictions"
      ]
    },
    {
      "metadata": {
        "id": "L-4-EpsVbNoh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred_list = []\n",
        "\n",
        "for i in range(config.n_folds):\n",
        "    pred_list.append(np.load(os.path.join(dir_pred, 'test_pred_%d.npy'%i)))\n",
        "    \n",
        "prediction = np.ones_like(pred_list[0])\n",
        "\n",
        "# Taking a geometric mean of the probabilities\n",
        "for pred in pred_list:\n",
        "    prediction = prediction*pred\n",
        "prediction_gm = prediction**(1./len(pred_list))\n",
        "\n",
        "# Make a submission file\n",
        "top_3 = np.array(labels)[np.argsort(-prediction_gm, axis=1)[:, :3]]\n",
        "\n",
        "predicted_labels = [' '.join(list(x)) for x in top_3]\n",
        "\n",
        "submission = pd.read_csv(os.path.join(dir_data, 'sample_submission.csv'))\n",
        "\n",
        "submission['label'] = predicted_labels\n",
        "submission[['fname', 'label']].to_csv(os.path.join(dir_data, 'submission.csv'), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3vHWTByy9oG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now save the logs, pr"
      ]
    },
    {
      "metadata": {
        "id": "R7FZv0c4mbxV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "datetime_now = str(datetime.now()).replace('-','').replace(':','').replace(' ','')\n",
        "datetime_now = datetime_now[:datetime_now.find('.')]\n",
        "datetime_now = datetime_now[4:8] + '_' + datetime_now[-6:-2]\n",
        "\n",
        "# save the logs\n",
        "zipname = datetime_now + '_log.zip'\n",
        "!zip -r /content/\"$zipname\" /content/logs\n",
        "files.download(os.path.join(dir_data, zipname))\n",
        "\n",
        "# save the preds\n",
        "zipname = datetime_now + '_pred.zip'\n",
        "!zip -r /content/\"$zipname\" /content/pred\n",
        "files.download(os.path.join(dir_data, zipname))\n",
        "\n",
        "# save the submission\n",
        "zipname = datetime_now + '_submission.zip'\n",
        "!zip -r /content/\"$zipname\" /content/submission.csv\n",
        "files.download(os.path.join(dir_data, zipname))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mcAlnIYuvQT4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}